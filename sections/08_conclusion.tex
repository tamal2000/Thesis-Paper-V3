% inital part of the conclusion
Trade fraud is not only causing economic damage to the business and their respective financial institutions but also disrupts the overall economy. Seldom fraudulent companies use the fund for terrorism, human rights violation, money laundering. Hence this is important to have a concrete solution for preventing fraudulent cases using existing best practices with the help of cutting edge technologies like artificial intelligence. 

The main goal of the current study was to determine a way to extract data from real-world information from historical data by taking a data-driven data mining approach and preparing and finding a suitable model to find patterns in the data to identify suspicious companies. The structure and procedure of the paper showed how an end to end process can be implemented to generate important features and apply machine learning models to classify high imbalanced datasets. 

\subsection{Finding}
From the exploratory data analysis section, we have seen that it is possible to generate important features by following the data-driven approach to extract data. Many of the features that we have engineered looked promising and provides indications of suspicious businesses. It is worth mentioning that while generating new features, it is very important to avoid understanding human biases and avoid them for the model. 

The performance results sections give us the indication that for real-world data like this which has a class imbalance, lots of missing data, and not having a clear dataset, Random Forest models give the best results. 

\subsection{Limitations}
There are several obstacles while preparing the data set and building the machine learning model. The major limitations are missing values, the volume of unstructured data. Considering it takes long sessions to generate each feature, the time and resources are also major constraints. On top of it, as most of the features are generated based on the input from the experts, there is a possible opportunity for selection biases. 



